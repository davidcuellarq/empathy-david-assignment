{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74b00091",
   "metadata": {},
   "source": [
    "# control_group_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21566614",
   "metadata": {},
   "source": [
    "In this notebook it'll show the models I decided to use to predict the the control group model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77abb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import cross_validate, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n",
    "from sklearn.model_selection import KFold, GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a20ced33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features from control  \n",
    "data = pd.read_csv('control_final_features.csv')\n",
    "\n",
    "# Scale data for better perfomance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Extract name of columns in df as a list, remove the participant name and empathy total\n",
    "columns = list(data.columns[1:-1])\n",
    "\n",
    "# Scale data by columns \n",
    "data[columns] = scaler.fit_transform(data[columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31959419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant name</th>\n",
       "      <th>Pupil diameter left</th>\n",
       "      <th>Pupil diameter right</th>\n",
       "      <th>Gaze point X (MCSnorm)</th>\n",
       "      <th>Gaze point Y (MCSnorm)</th>\n",
       "      <th>Total Score extended</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.818307</td>\n",
       "      <td>-0.771083</td>\n",
       "      <td>-0.680542</td>\n",
       "      <td>-0.576123</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.920335</td>\n",
       "      <td>-1.064625</td>\n",
       "      <td>0.593515</td>\n",
       "      <td>0.172209</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.604592</td>\n",
       "      <td>-0.631356</td>\n",
       "      <td>0.572094</td>\n",
       "      <td>0.016587</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.576383</td>\n",
       "      <td>-0.453767</td>\n",
       "      <td>-0.528207</td>\n",
       "      <td>0.032114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.175007</td>\n",
       "      <td>-1.012498</td>\n",
       "      <td>0.880017</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Participant name  Pupil diameter left  Pupil diameter right  \\\n",
       "0                 2            -0.818307             -0.771083   \n",
       "1                 2            -0.920335             -1.064625   \n",
       "2                 2            -0.604592             -0.631356   \n",
       "3                 2            -0.576383             -0.453767   \n",
       "4                 4            -1.175007             -1.012498   \n",
       "\n",
       "   Gaze point X (MCSnorm)  Gaze point Y (MCSnorm)  Total Score extended  \n",
       "0               -0.680542               -0.576123                     3  \n",
       "1                0.593515                0.172209                     3  \n",
       "2                0.572094                0.016587                     3  \n",
       "3               -0.528207                0.032114                     3  \n",
       "4                0.880017                0.009025                     2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9135d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://machinelearningmastery.com/training-validation-test-split-and-cross-validation-done-right/\n",
    "\n",
    "# Train-test split, intentionally use shuffle=False\n",
    "X = data.iloc[:,1:-1]\n",
    "Y = data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2a13688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two models: Polynomial and linear regression\n",
    "degree = 2\n",
    "polyreg = make_pipeline(PolynomialFeatures(degree), LinearRegression(fit_intercept=False))\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67df9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "scoring = \"neg_root_mean_squared_error\"\n",
    "polyscores = cross_validate(polyreg, X_train, Y_train, scoring=scoring, return_estimator=True)\n",
    "linscores = cross_validate(linreg, X_train, Y_train, scoring=scoring, return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ab05017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 1.4294543428318127\n",
      "Mean validation RMSE: 0.6262526293083622\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model and evaluate\n",
    "linreg = sklearn.base.clone(linreg)\n",
    "linreg.fit(X_train, Y_train)\n",
    "print(\"Test set RMSE:\", mean_squared_error(Y_test, linreg.predict(X_test), squared=False))\n",
    "print(\"Mean validation RMSE:\", -linscores[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c4d92",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eeb379cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression CV scores:  [0.45833333 0.58333333 0.375      0.17391304 0.34782609]\n",
      "Mean CV score:  0.3876811594202899\n",
      "Standard deviation of CV scores:  0.13469784618491754\n"
     ]
    }
   ],
   "source": [
    "# create a linear regression model\n",
    "logreg_model = LogisticRegression()\n",
    "\n",
    "# perform cross-validation with 5 folds\n",
    "scores = cross_val_score(logreg_model, X, Y, cv=5)\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(\"Logistic Regression CV scores: \", scores)\n",
    "print(\"Mean CV score: \", scores.mean())\n",
    "print(\"Standard deviation of CV scores: \", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a7f5e",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "322343d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regression CV scores:  [-0.28255721 -5.77269188 -0.29291182 -5.25200644 -0.45120256]\n",
      "Mean CV score:  -2.410273982025548\n",
      "Standard deviation of CV scores:  2.538883986284045\n"
     ]
    }
   ],
   "source": [
    "# create a support vector regression model with a radial basis function kernel\n",
    "svr_model = SVR(kernel='rbf')\n",
    "\n",
    "# perform cross-validation with 5 folds\n",
    "scores = cross_val_score(svr_model, X, Y, cv=5)\n",
    "\n",
    "# print the mean and standard deviation of the scores\n",
    "print(\"Support Vector Regression CV scores: \", scores)\n",
    "print(\"Mean CV score: \", scores.mean())\n",
    "print(\"Standard deviation of CV scores: \", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8be99",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da8abdf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 11ms/step - loss: 5.2530\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.0853\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 4.9117\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 4.7520\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.6026\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.4488\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 4.3005\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 4.1598\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 4.0181\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.8809\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "MSE:  0.6052273646846217\n",
      "MAE:  0.6584987087901366\n",
      "R-squared:  -1.033587313192247\n"
     ]
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# fit the model on training data\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# predict on test data\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Print MSE, MAE, and R-squared score\n",
    "print(\"MSE: \", mean_squared_error(Y_test, Y_pred))\n",
    "print(\"MAE: \", mean_absolute_error(Y_test, Y_pred))\n",
    "print(\"R-squared: \", r2_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a5140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
